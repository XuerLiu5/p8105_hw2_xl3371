---
title: "p8105_hw2_xl3371"
author: "Xuer Liu"
date: "2023-10-01"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

### First, clean the data in pols-month.csv
```{r, message=FALSE}
pols_month_clean = read_csv("./data/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(year = as.integer(year),
         day = as.integer(day)) %>%
  mutate(month = case_match(
    month, 
    "01" ~ "Jan",
    "02" ~ "Feb",
    "03" ~ "Mar",
    "04" ~ "Apr",
    "05" ~ "May",
    "06" ~ "Jun",
    "07" ~ "Jul",
    "08" ~ "Aug",
    "09" ~ "Sep",
    "10" ~ "Oct",
    "11" ~ "Nov",
    "12" ~ "Dec"
  )) %>%
  mutate(
    president = ifelse(prez_dem==1, "dem", "gop")) %>%
  select(-c(prez_gop, prez_dem, day))
```

### Second, clean the data in snp.csv
```{r}
snp_clean = read.csv("./data/snp.csv") %>%
  janitor::clean_names() %>%
  mutate(date = as.Date(date, format = "%m/%d/%y")) %>%
  separate(date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(year = as.integer(year),
         year = ifelse(year > 2049, year - 100, year),
    month = case_match(month, 
    "01" ~ "Jan",
    "02" ~ "Feb",
    "03" ~ "Mar",
    "04" ~ "Apr",
    "05" ~ "May",
    "06" ~ "Jun",
    "07" ~ "Jul",
    "08" ~ "Aug",
    "09" ~ "Sep",
    "10" ~ "Oct",
    "11" ~ "Nov",
    "12" ~ "Dec"
  )) %>%
  select(year, month, close) %>%
  arrange(year, month) %>%
  relocate(year, month)
```

### Third, tidy the unemployment data
```{r, message=FALSE}
unemployment_clean = read.csv("./data/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "umemployment_rate"
  ) %>%
  rename(year = Year) %>%
  mutate(year = as.integer(year))
```

### Merge three datasets into result
```{r}
pols_snp = left_join(pols_month_clean, snp_clean, by = c("year","month"))
result = left_join(pols_snp, unemployment_clean, by = c("year","month"))
```

### Description
1. The `pols_month_clean` dataset contains `r ncol(pols_month_clean)` variables and `r nrow(pols_month_clean)` observations. The key variables include year, month, and president (elected president's party). This dataset tells us about the party affiliation distribution (democrat or republican) for governors and senators from years `r range(pols_month_clean$year)[1]` to `r range(pols_month_clean$year)[2]`. 
2. The `snp_clean` dataset contains `r ncol(snp_clean)` variables and `r nrow(snp_clean)` observations, ranging from `r range(snp_clean$year)[1]` to `r range(snp_clean$year)[2]`. The key variables include year, month, and close (closing values of stock index).
3. The `unemployment_clean` dataset contains `r ncol(unemployment_clean)` variables and `r nrow(unemployment_clean)` observations, ranging from `r range(unemployment_clean$year)[1]` to `r range(unemployment_clean$year)[2]`. The key variables include year, month, and unemployment rate.
4. The `result` dataset merges the above three datasets, with `r ncol(result)` columns and `r nrow(result)` rows. The data ranges from `r range(result$year)[1]` to `r range(result$year)[2]`, indicating the potential correlation between politics, closing value of stock, and unemployment.

## Problem 2

### Import and clean data from Mr. Trash Wheel sheet
```{r}
mr_tw = 
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N586") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.integer(year),
         type = "Mr",
         homes_powered = (weight_tons * 500) / 30) 
  
```

### Import and clean data from Professor Trash Wheel sheet
```{r}
prof_tw =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M106") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.integer(year),
         type = "Professor",
         homes_powered = (weight_tons * 500) / 30) 
```

### Import and clean data from Gwynnda Trash Wheel sheet
```{r}
gw_tw =
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L157") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.integer(year),
         type = "Gwynnda",
         homes_powered = (weight_tons * 500) / 30) 
```

### Merge datasets
```{r}
trashwheel_merge = 
  bind_rows(mr_tw, prof_tw, gw_tw) %>% 
  janitor::clean_names() %>% 
  select(type, dumpster, everything()) %>% 
  arrange(type, dumpster)
```

### Description
1. The number of observations in `mr_tw` dataset is `r nrow(mr_tw)`. The key variables include `dumpster`, `weight_tons`, and `homes_powered`.
2. The number of observations in `prof_tw` dataset is `r nrow(prof_tw)`. The key variables include `dumpster`, `weight_tons`, and `homes_powered`.
3. The number of observations in `gw_tw` dataset is `r nrow(gw_tw)`. The key variables include `cigarette_butts`, `weight_tons`, and `homes_powered`.
4. There are `r ncol(trashwheel_merge)` variables and `r nrow(trashwheel_merge)` observations in this combined dataset. The key variables include the types of the trash wheel, either `Mr`, `Professor`, or `Gwynnda`, `weight_tons`, `cigarette_butts`, and other similar items. 

The total weight of trash collected by Professor Trash Wheel is `r sum(filter(trashwheel_merge, type=="Professor")$weight_tons)`

The total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum((filter(trashwheel_merge, type == "Gwynnda", year == 2021, month == "July"))$cigarette_butts)`.

## Problem 3

### Import, clean, and tidy the dataset of baseline demographics
```{r, warning=FALSE}
baseline = read.csv("./data/MCI_baseline.csv", skip = 1) %>%
  janitor::clean_names() %>%
  mutate(sex = ifelse(sex == 1, "male", "female"),
         apoe4 = ifelse(apoe4 == 1, "carrier", "non_carrier"),
         age_at_onset = as.numeric(age_at_onset))

baseline_mci = baseline %>%
  drop_na(age_at_onset)
```
Description: \
First import the csv data of baseline demographics and skip the first row which is description. \
Use `janitor` to rename the variables, and use `mutate` function to convert `sex` and `apoe4` into factor variables and convert `age_at_onset` to numeric variable. \
Finally use `drop_na` function to remove the observations who do not meet the stated inclusion criteria. \
There are `r nrow(baseline_mci)` observations and `r ncol(baseline_mci)` variables left in the dataset after cleaning.

`r nrow(baseline)` participants were recruited, and only `r nrow(baseline_mci)` develop MCI. \
The average baseline age is `r round(mean(baseline_mci$age_at_onset),2)`, and the proportion of women in the study are APOE4 carriers is `r round(nrow(filter(baseline_mci, sex == "female", apoe4 == "carrier"))/nrow(filter(baseline_mci, sex == "female")) * 100, 2)`%.


### Import, clean, and tidy the dataset of longitudinally observed biomarker values
```{r, warning=FALSE}
amyloid = read.csv("./data/mci_amyloid.csv", skip = 1) %>%
  janitor::clean_names() %>%
  rename(id = study_id) %>%
  mutate_all(as.numeric)
```
Description: \
First import the csv data of longitudinally observed biomarker values and skip the first row which is description. \
Then, rename the variable `study_id` to `id` in order to prepare for merging with the `baseline_mci` dataset. \
And use `mutate_all` function to convert all variables to numeric variables. \
The dataset `amyloid` contains `r ncol(amyloid)` variables and `r nrow(amyloid)` observations. The key variables include `r names(amyloid)`.

### Check whether some participants appear in only the baseline or amyloid datasets
```{r}
baseline_only = anti_join(baseline_mci, amyloid, by = "id") 
```
By checking, there are `r nrow(anti_join(baseline_mci, amyloid, by = "id"))` participants appear in only the baseline dataset, their `id` are `14`, `49`, and `268`. And there are `r nrow(anti_join(amyloid, baseline, by = "id"))` participants only appear in the amyloid dataset.

### Merge
```{r}
baseline_amyloid_merge = inner_join(baseline_mci, amyloid, by = "id") %>%
  drop_na()
```
In order to only retain the participants who appear in both datasets, I combined the two datasets by `id`. \
The resulting dataset contains `r nrow(baseline_amyloid_merge)` observations and `r ncol(baseline_amyloid_merge)` variables which are `r names(baseline_amyloid_merge)` after merging.

```{r}
write.csv(baseline_amyloid_merge, "./data/result_merge.csv")
```

